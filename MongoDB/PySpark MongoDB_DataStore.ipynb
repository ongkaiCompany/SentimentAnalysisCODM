{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/23 08:18:26 WARN Utils: Your hostname, jupy-06 resolves to a loopback address: 127.0.1.1; using 10.123.51.206 instead (on interface ens18)\n",
      "24/04/23 08:18:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/23 08:18:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read CSV from HDFS and send to MongoDB\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting Raw Youtube Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubePath = \"hdfs://10.123.51.194/user/g23/spark_hdfs_webScrapingv3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/23 08:18:32 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yt_df = spark.read.csv(youtubePath, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------+-------+--------------------+\n",
      "|        comment_text|      comment_author|votes|dislikes|replies|                  id|\n",
      "+--------------------+--------------------+-----+--------+-------+--------------------+\n",
      "|Just wanted to sa...|          @J3FFBezos|   11|       0|      1|UgwNKGEArXPJaKx-y...|\n",
      "|The first LAN eve...|       @josepila9310|    5|       0|   NULL|UgxY1qWMgGKDLtXZv...|\n",
      "|EXCELENTE CAMPEÃ“N...|@gerardomartinez6063|    0|       0|   NULL|UgzR-GPIW5LZERY4a...|\n",
      "|Yrr me ye nhi sam...|            @Amaze__|    1|       0|   NULL|UgwjTC9JHr9ux3lYv...|\n",
      "|ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘ðŸ‘‘?...|@gerardomartinez6063|    0|       0|   NULL|UgwScr2cyFWXV-Ff3...|\n",
      "|Just curious wasn...|     @samuelconn3571|    0|       0|   NULL|Ugx7soqAm0113R5ju...|\n",
      "|he always know wh...|       @cjkamela4896|    2|       0|   NULL|Ugx1leLq0i0wtMPlh...|\n",
      "|Why do not you do...|   @silverbullet4966|    0|       0|   NULL|UgyuuSJVHHUP6Go4N...|\n",
      "|Bring back the ak...|            @gads994|    1|       0|   NULL|UgywHiJjgRF92C1U7...|\n",
      "|Add ðŸªšðŸ”—â›½ðŸ©¸CHAIN ...|   @rohaanshahab8414|    0|       0|   NULL|UgxCo5jR_AH64ouzO...|\n",
      "|Unfortunately I w...| @thedevilhunter0013|    1|       0|   NULL|UgyC4ObX4L2G6Oojp...|\n",
      "|Bro, as a long ti...|   @arshadjassim4913|    1|       0|   NULL|Ugy9F-LQsdCmPntNj...|\n",
      "|What determines w...|     @anderjantvcodm|    3|       0|      1|UgytWFMX2xA7jSQBf...|\n",
      "|Maybe have a numb...|       @TJ4PRESIDENT|    1|       0|   NULL|Ugy92bT5N6O3PHinX...|\n",
      "|This is like sayi...|            @ray6808|    0|       0|   NULL|UgyFhmTDnTQhSdSvV...|\n",
      "|This is cool but ...|            @Amircrl|    2|       0|   NULL|UgwaN72a0GmyxVf8L...|\n",
      "|I remember watchi...|         @Newgrfx321|    1|       0|   NULL|Ugx_JMGR-dQWC8HMU...|\n",
      "|Como lo haces par...|   @feliperendon6387|    1|       0|   NULL|UgyHQXHAJuCkjGooA...|\n",
      "|Codm need a Codm ...|       @adityasai311|    1|       0|   NULL|UgzNBzWU1nuBOhCUn...|\n",
      "|bro can I also re...|      @aadigupta7777|    0|       0|   NULL|Ugx2I2A4IFHtXgXks...|\n",
      "+--------------------+--------------------+-----+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yt_df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting Raw Reddit Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditPath = \"hdfs://10.123.51.194/user/g23/spark_hdfs_data_crawlingv3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_df = spark.read.csv(redditPath, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+----------------+--------------------+--------------------+-------------+----------+---------------+------------+\n",
      "|               title|post_score|post_id|       subreddit|                 url|             comment|comment_score|comment_id|comment_created|reply_number|\n",
      "+--------------------+----------+-------+----------------+--------------------+--------------------+-------------+----------+---------------+------------+\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|Please report any...|            1|   kvi01uq|  1.710803096E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|Hey devs, the new...|           27|   kurfpzv|  1.710375314E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|     First.#ALCATRAZ|           42|   kur9acw|  1.710372967E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|So youâ€™re removin...|           15|   kurm9ad|   1.71037771E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|Dear social media...|           24|   kura02r|  1.710373228E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|Will BR get a mod...|           12|   kurcofs|  1.710374216E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|What's your repla...|            5|   kurj9or|  1.710376609E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|Thanks for the ef...|            9|   kurep73|  1.710374946E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|BRING BACK SHOOT ...|            5|   kurdfjl|   1.71037449E9|          75|\n",
      "|Call of Duty: Mob...|         7|1be6f25|callofdutymobile|https://www.reddi...|u/COD_Mobile_Offi...|            3|   kurrxk9|  1.710379844E9|          75|\n",
      "+--------------------+----------+-------+----------------+--------------------+--------------------+-------------+----------+---------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rd_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting Raw Kaggle Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/g23/CallOfDuty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|             reviews|ratings|\n",
      "+--------------------+-------+\n",
      "|I've been playing...|      4|\n",
      "|An annoying exper...|      1|\n",
      "|I love the game t...|      3|\n",
      "|I've been playing...|      4|\n",
      "|An annoying exper...|      1|\n",
      "|COD happens to be...|      2|\n",
      "|Codm is awesome a...|      5|\n",
      "|Easy y 3 stars, I...|      3|\n",
      "|Wonderful concept...|      4|\n",
      "|I'm simply in lov...|      5|\n",
      "|Reminds me of the...|      5|\n",
      "|I love this game ...|      5|\n",
      "|I really, really ...|      5|\n",
      "|I love this app, ...|      5|\n",
      "|I've played lots ...|      5|\n",
      "|Gameplay is smoot...|      2|\n",
      "|6/3/2022 update. ...|      4|\n",
      "|I've had my ups a...|      5|\n",
      "|I love the game, ...|      3|\n",
      "|Amazing game, gre...|      4|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "spark_df = spark_df.withColumn(\"reviews\", regexp_replace(\"reviews\", \"[\\n\\r]\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgPath = \"hdfs://10.123.51.194/user/g23/hdfs_CallOfDutyv2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df.write.option(\"header\",True).csv(kgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df = spark.read.csv(kgPath, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Putting Data in MongoDB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "uri = \"mongodb+srv://user:password@cluster0.6phfn6j.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For Youtube Data\n",
    "mydb = client[\"AssignmentRawData\"]\n",
    "ytCol = mydb[\"YoutubeRawData\"]\n",
    "\n",
    "records = yt_df.collect()\n",
    "documents = [row.asDict() for row in records]\n",
    "ytCol.insert_many(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For Reddit Data\n",
    "mydb = client[\"AssignmentRawData\"]\n",
    "rdCol = mydb[\"RedditRawData\"]\n",
    "\n",
    "records = rd_df.collect()\n",
    "documents = [row.asDict() for row in records]\n",
    "rdCol.insert_many(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For Kaggle Data\n",
    "mydb = client[\"AssignmentRawData\"]\n",
    "kgCol = mydb[\"KaggleRawData\"]\n",
    "\n",
    "records = kg_df.collect()\n",
    "documents = [row.asDict() for row in records]\n",
    "kgCol.insert_many(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
